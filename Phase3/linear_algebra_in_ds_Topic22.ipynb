{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra Applications in Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://www.analyticsvidhya.com/blog/2019/07/10-applications-linear-algebra-data-science/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from seaborn import load_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "gems = load_dataset('diamonds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors and Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of linear algebra, a single number is a 0-dimensional entity called a **scalar**. But it is often useful to have data in the form of a 1-dimensional object called a **vector**, which can be thought of as a list of scalars. Think here of a `pandas` Series. And in addition to the values that compose the vector, we can characterize the vector as a whole as having a **magnitude** and a **direction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAGiCAYAAABOCgSdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtiklEQVR4nO3df3zP9f7/8ft+tKnZJsv8yIaclN8Kh/lNqIWMFCWN5KSW0tIPdTrJcZrK6dfxpZx+oFokhnMODoUhhomSJKI2+f1r7214Y3t//3h+2klRe297vV/vH7fr5fK6nJ5v7x8P0/G+93o+ns9nkMvlcgkAAMAiwXYXAAAA/BthAwAAWIqwAQAALEXYAAAAliJsAAAASxE2AACApQgbAADAUoQNAABgKcIGAACwFGEDAABYyu2w8eOPP+quu+5STEyMLrvsMrVo0UKbNm2yojYAAOAHQt158vHjx9W+fXt17dpVixcvVmxsrL777jtVqVLFovIAAICvC3LnILYnn3xSn332mVavXm1lTQAAwI+4FTYaNWqkG2+8UXv37lVmZqauvPJKPfDAAxoxYsRFX+N0OuV0OkvGxcXFOnbsmGJiYhQUFFS+6gEAgEe4XC7l5+erVq1aCg52swvD5Ybw8HBXeHi4a+zYsa7PP//c9cYbb7gqVarkmjFjxkVf8+yzz7okcXFxcXFxcfnBlZub6050cLlcLpdbdzbCwsLUqlUrrV27tuSxhx56SBs3btS6desu+Jpf3tnIy8tTfHy8cnNzFRUVVdqPBgAANnI4HIqLi9OJEycUHR3t1mvdahCtWbOmGjVqdN5jDRs21Ny5cy/6mvDwcIWHh//q8aioKMIGAAA+piwtEG5NurRv3147duw477Fvv/1WderUcfuDAQBAYHArbDzyyCPKysrS888/r127dik9PV3Tpk1TSkqKVfUBAAAf51bYaN26tTIyMvThhx+qSZMm+utf/6pXX31VgwcPtqo+AADg49xqEK0IDodD0dHRysvLo2cDAAAfUZ7vb85GAQAAliJsAAAASxE2AACApQgbAADAUoQNAABgKcIGAACwFGEDAABYirABAAAsRdgAAACWImwAAABLETYAAIClCBsAAMBShA0AAGApwgYAALAUYQMAAFiKsAEAACxF2AAAAJYibAAAAEsRNgAAgKUIGwAAwFKEDQAAYCnCBgAAsBRhAwAAWIqwAQAALEXYAAAAliJsAAAASxE2AACApQgbAADAUoQNAABgKcIGAACwFGEDAABYirABAAAsRdgAAACWImwAAABLETYAAIClCBsAAMBShA0AAGApwgYAALAUYQMAAFiKsAEAACxF2AAAAJYibAAAAEsRNgAAgKUIGwAAwFKEDQAAYCnCBgAAsBRhAwAAWIqwAQAALEXYAAAAlnIrbIwbN05BQUHnXTVq1LCqNgAA4AdC3X1B48aN9cknn5SMQ0JCKrQgAADgX9wOG6GhoW7dzXA6nXI6nSVjh8Ph7kcCAAAf5nbPxs6dO1WrVi3Vq1dPgwYN0u7du3/z+WlpaYqOji654uLiylwsAADwPUEul8tV2icvXrxYJ0+eVIMGDXTw4EFNmDBB33zzjbZt26aYmJgLvuZCdzbi4uKUl5enqKio8v8OAACA5RwOh6Kjo8v0/e1W2PilwsJC1a9fX48//rhSU1NL9ZryFAsAAOxRnu/vci19jYiIUNOmTbVz587yvA0AAPBj5QobTqdT27dvV82aNSuqHgAA4GfcChtjxoxRZmam9uzZo/Xr12vAgAFyOBxKTk62qj4AAODj3Fr6unfvXt1xxx06cuSIqlWrprZt2yorK0t16tSxqj4AAODj3Aobs2bNsqoOAADgpzgbBQAAWIqwAQAALEXYAAAAliJsAAAASxE2AACApQgbAADAUoQNAABgKcIGAACwFGEDAABYirABAAAsRdgAAACWImwAAABLETYAAIClCBsAAMBShA0AAGApwgYAALAUYQMAAFiKsAEAACxF2AAAAJYibAAAAEsRNgAAgKUIGwAAwFKEDQAAYCnCBgAAsBRhAwAAWIqwAQAALEXYAAAAliJsAAAASxE2AACApQgbAADAUoQNAABgKcIGAACwFGEDAABYirABAAAsRdgAAACWImwAAABLETYAAIClCBsAAMBShA0AAGApwgYAALAUYQMAAFiKsAEAACxF2AAAAJYibAAAAEsRNgAAgKUIGwAAwFKEDQAAYCnCBgAAsFS5wkZaWpqCgoI0evToCioHAAD4mzKHjY0bN2ratGlq1qxZRdYDAAD8TGhZXlRQUKDBgwfrn//8pyZMmFDRNQFAhSksrJj32bNHOntWuu66ink/IJCUKWykpKSoV69e6t69+++GDafTKafTWTJ2OBxl+UgAKJPKlSvuvWrVkjZuNP8LoPTcDhuzZs3Spk2blJ2dXarnp6Wl6bnnnnO7MADwNvv2SSdP2l0F4Hvc6tnIzc3Vww8/rA8++ECVKlUq1WvGjh2rvLy8kis3N7dMhQJAWRQUlO06flwaMeLX71ezpud/D4CvC3K5XK7SPnn+/Pnq16+fQkJCSh4rKipSUFCQgoOD5XQ6z/u1C3E4HIqOjlZeXp6ioqLKXjkAWOToUem226QVK6SgIGncOOnZZ82vFRRIERG2lgfYojzf325No9xwww3aunXreY8NGzZM1157rZ544onfDRoA4O2+/lq65Rbpu+9Mv0d6utSt2//CBgD3uRU2IiMj1aRJk/Mei4iIUExMzK8eBwBfs2iRNGiQlJ8v1a0r/etfUpMmFbeiBQhU7CAKIOC5XNKkSVLv3iZodO5sVp3w31BAxSjT0tefW7lyZQWUAQD2OH1auu8+aeZMM77vPun116WwMHvrAvxJucMGAPiqAwekfv2krCwpJER67TXpgQdMUyiAikPYABCQPv9c6ttX2rtXuvxyac4c6YYb7K4K8E/0bAAIOHPmSB06mKBx7bXS+vUEDcBKhA0AAaO42Cxhvf126dQp6aabzBTK1VfbXRng35hGARAQCgul5GRp7lwzfvRR6YUXTK8GAGsRNgD4vR9+MP0ZX3xhVplMm2aCBwDPIGwA8GuffSb17y8dOiTFxkoZGVK7dnZXBQQWejYA+K1335W6djVBo0ULs1EXQQPwPMIGAL9TVGR6Mu65Rzp7Vrr1VmnNGik+3u7KgMBE2ADgV06cMNuOv/yyGY8bJ330ESe1AnaiZwOA39i5U+rTR9qxQ7r0UrMF+YABdlcFgLABwC8sW2b2zzhxQoqLkxYskK67rmLeOyLCHNYGoGyYRgHg01wu6R//kBITTdBISJA2bKi4oAGg/AgbAHzWmTPmlNaHHjJNocnJ0ooVUo0adlcG4OeYRgHgk44cMatMVq0yp7S+9JKUmsqJrYA3ImwA8Dlbt0q33CJ9/70UFSV9+KF08812VwXgYphGAeBTFiwwG3N9/71Uv745SI2gAXg3wgYAn+BySWlpUr9+UkGBORJ+wwapYUO7KwPwewgbALzeqVPSXXdJTz1lQkdKirR4sVS1qt2VASgNejYAeLV9+6SkJHOuSWioNHmyWYECwHcQNgB4rY0bTdDYt0+KiZE+/ljq0sXuqgC4i2kUAF4pPV3q2NEEjcaNTX8GQQPwTYQNAF6luNj0ZgweLDmd5qyTtWulq66yuzIAZUXYAOA18vOl/v3NqhNJevJJKSPD7KUBwHfRswHAK+zZYzbq+uorKTxceustswIFgO8jbACwXWamOQr+yBGpZk1zN6NNG7urAlBRmEYBYKtp06Tu3U3QaNXKrEAhaAD+hbABwBbnzpnTWu+7z/zzoEHmULUrr7S7MgAVjWkUAB53/Lh0++3SJ5+Y8YQJZgUKJ7YC/omwAcCjvvnGNILu3ClFREjvvWfOOwHgvwgbADxmyRIzXZKXJ9WpIy1cKDVrZndVAKxGzwYAy7lc0ssvS716maDRsaNpBCVoAIGBsAHAUk6ndM890qOPmt1B773X9GpUq2Z3ZQA8hWkUAJY5eNDsCLp2rRQcLL3yijRqFI2gQKAhbACwxJYtphE0N1eKjpY++kjq2dPuqgDYgWkUABVu7lypfXsTNBo0MCe2EjSAwEXYAFBhXC5p/Hiz9fjJk9KNN0rr15vAASBwMY0CoEKcPCkNHSrNmWPGo0dLL70khfK3DBDw+GsAQLnl5kp9+0qbN0uXXCK98YZZgQIAEmEDQDllZUlJSWblSbVq0rx5UocOdlcFwJvQswGgzGbOlDp3NkGjWTOzURdBA8AvETYAuK2oSHrsMSk5WTpzxpxt8tlnZgtyAPglwgYAtzgcZv+MSZPM+JlnpI8/lipXtrcuAN6Lng0ApbZrlwka27dLlSpJ06dLAwfaXRUAb0fYAFAqy5dLt90mHTsmXXmltGCB1LKl3VUB8AVMowD4XVOmmB1Ajx2T2rQxjaAEDQClRdgAcFFnz0r33y+lpJim0CFDpJUrpZo17a4MgC9hGgXABR09arYdX7nSnNI6caJZgcKJrQDcRdgA8CvbtplG0N27zSqTDz+Ueve2uyoAvsqtaZSpU6eqWbNmioqKUlRUlBISErR48WKragNgg3//W0pIMEHjqqvMDqEEDQDl4VbYqF27tiZOnKjs7GxlZ2erW7du6tu3r7Zt22ZVfQA8xOWSXnjB3NHIz5e6dDFHwzdubHdlAHxdkMvlcpXnDapWraqXXnpJw4cPL9XzHQ6HoqOjlZeXp6ioqPJ8NIAKcvq0NGKE9P77Znz//dJrr5lD1QBAKt/3d5l7NoqKijRnzhwVFhYqISHhos9zOp1yOp3nFQvAe+zfb7YbX79eCgmRXn9deuABu6sC4E/cDhtbt25VQkKCTp8+rcqVKysjI0ONGjW66PPT0tL03HPPlatIANbYtMkcDf/jj9Lll5ttx7t1s7sqAP7G7WmUM2fOKCcnRydOnNDcuXP11ltvKTMz86KB40J3NuLi4phGAWw2e7Y0bJh06pTUsKG0cKH0hz/YXRUAb1WeaZRy92x0795d9evX15tvvlmq59OzAdiruFh69llpwgQzvvlmKT1dio62ty4A3s2Wno2fuFyu8+5cAPBeBQXS3XdLGRlm/NhjUlqa6dUAAKu4FTaeeuopJSYmKi4uTvn5+Zo1a5ZWrlypJUuWWFUfgAryww9mWeuXX0phYdI//2mCBwBYza2wcfDgQQ0ZMkT79+9XdHS0mjVrpiVLlqhHjx5W1QegAqxZI/XvLx0+LFWvbu5s/MYiMgCoUG6FjbffftuqOgBY5O23zb4ZZ89K111njoaPi7O7KgCBhFNfAT917pz0yCPSvfeaoHHbbdLq1QQNAJ7HQWyAHzpxQho4UFq61IzHj5f+/GdObAVgD8IG4Ge+/Vbq08f872WXSTNnSrfeandVAAIZYQPwI0uXmjsaJ06Y6ZKFC6UWLeyuCkCgo2cD8AMulzk4LTHRBI127aSNGwkaALwDYQPwcWfOSH/6kzR6tNkddNgwaflys8QVALwB0yiADzt82PRjrF4tBQdLkyaZ0EEjKABvQtgAfNSXX5odQX/4QYqKMger3XST3VUBwK8xjQL4oPnzTV/GDz+Yk1rXrydoAPBehA3Ah7hc0t/+JvXrJxUWSt27m6Bx7bV2VwYAF8c0CuAjTp2S7rlHmjXLjEeNkl5+WQrl/8UAvBx/TQE+4Mcfpb59pU2bTLiYMkUaMcLuqgCgdAgbgJdbv15KSpIOHJCuuEKaO1fq1MnuqgCg9OjZALzYBx9InTuboNGkibRhA0EDgO8hbABeqLhYGjtWuusuyek0S1zXrpXq1bO7MgBwH2ED8DL5+WbaZOJEMx47VsrIkCIjbS0LAMqMng3Ai+zebe5ibNsmVaokvf22dOeddlcFAOVD2AC8xMqV0oAB0tGjUs2a0oIFUuvWdlcFAOXHNArgBd58U+rRwwSN1q2l7GyCBgD/QdgAbHT2rPTgg9LIkdK5c9Idd0iZmVKtWnZXBgAVh2kUwCbHjkm33y59+qkZP/+89OSTnNgKwP8QNgAbbN9uGkF37ZIqV5bef9/sEAoA/oiwAXjYokVmusThkOrWlRYulJo2tbsqALAOPRuAh7hc0qRJUu/eJmh06mR2BCVoAPB3hA3AA5xOadgw6bHHTOgYMUJatkyqVs3uygDAeoQNlFi5cqXq1q3r1mumT5+uLl26WFKPvzhwQOraVZoxQwoJkV5/3Sx1DQuzuzIA8AzCBrzeuHHjFBQUdN5Vo0YNu8sqlc2bzX4Z69ZJVapIS5ZIo0ax4gRAYKFBFD6hcePG+uSTT0rGISEhNlZTOnPmSMnJ0qlT0jXXSP/6l3T11XZXBQCex50NXFRCQoKefPLJ8x47fPiwLrnkEq1YscKjtYSGhqpGjRolVzUvbnYoLpbGjTN7aJw6Jd10k5SVRdAAELgIG7iowYMH68MPP5TL5Sp5bPbs2apevbo6d+5c6vcZOXKkKleu/JtXTk7Ob77Hzp07VatWLdWrV0+DBg3S7t27y/z7slJhoQkZzz1nxqmp0r//baZQACBQMY2Cixo4cKAeeeQRrVmzRh07dpQkpaen684771RwcOlz6vjx4zVmzJjffE6t39ifu02bNpo5c6YaNGiggwcPasKECWrXrp22bdummJiYUtdhtZwcszHXli3SJZeYJtBhw+yuCgDsR9jARVWrVk09evTQBx98oI4dO2rPnj1at26dpk6d6tb7xMbGKjY2tsx1JCYmlvxz06ZNlZCQoPr162vGjBlKTU0t8/tWpLVrpX79pEOHpNhYad48qX17u6sCAO/ANAp+0+DBg/Xxxx/r7NmzSk9PV+PGjdW8eXO33qMiplF+LiIiQk2bNtXOnTvd/e1YYvp0s7T10CGpeXNp40aCBgD8HHc28JuSkpJ03333acmSJUpPT9eQIUPcfo/yTqP8ktPp1Pbt20umduxSVCQ98YT097+b8a23mr00IiJsLQsAvA5hA78pIiJCffv21TPPPKPt27frzjvvdPs9yjuNMmbMGPXp00fx8fE6dOiQJkyYIIfDoeTk5DK/Z3nl5ZnzTRYvNuO//EV69lnJjVYWAAgYhA38rsGDB6tXr17q1KmT4uPjPf75e/fu1R133KEjR46oWrVqatu2rbKyslSnTh2P1yJJO3eaE1u/+Ua69FJzN+O222wpBQB8AmEDv+vmm28+b/mrp82aNcu2z/6lTz81weL4cal2bWnBAun66+2uCgC8Gzd9gVJwuaTJk6UbbzRBo21b0whK0ACA30fYAH7HmTPSyJHmTJOiIunuu6UVKyQfOZ4FAGzHNApK1K1bV6NHj3brNS1atNDQoUMtqccbHDkiDRggZWaaw9NefFF69FEOUgMAdwS5PDwZ73A4FB0drby8PEVFRXnyowG3fPWVaQTds0eKjJQ+/FDq1cvuqgDAHuX5/mYaBbiAhQulhAQTNOrXNwepETQAoGwIG8DPuFxSWpqUlCQVFEjduknr10uNGtldGQD4LsIG8H9OnZLuukt66ikTOlJSpCVLJC866w0AfBINooCkffvM3YyNG6XQUOkf/zArUAAA5UfYQMDLzjZHw+/bJ1WtKn38sTlYDQBQMZhGQUD78EOpY0cTNBo1kjZsIGgAQEUjbCAgFRdLTz8t3XmndPq01Lu3tG6dWXkCAKhYboWNtLQ0tW7dWpGRkYqNjVVSUpJ27NhhVW2AJfLzpf79peefN+MnnpDmz5fY9gUArOFW2MjMzFRKSoqysrK0bNkynTt3Tj179lRhYaFV9QEV6vvvpfbtzQFq4eHSe+9JEydKISF2VwYA/qtcO4gePnxYsbGxyszMVKdOnUr1GnYQhV1WrZJuvdVsQV6jhrmb0aaN3VUBgG8oz/d3uVaj5OXlSZKqVq160ec4nU45nc6SscPhKM9HAmXy1lvSAw9IZ89KLVuaoFG7tt1VAUBgKHODqMvlUmpqqjp06KAmTZpc9HlpaWmKjo4uueLi4sr6kYDbzp2THn5YGjHCBI2BA80dDoIGAHhOmadRUlJS9J///Edr1qxR7d/4m/tCdzbi4uKYRoHljh834WLZMjP+61/NChRObAUA93l8GmXUqFFauHChVq1a9ZtBQ5LCw8MVHh5elo8BymzHDqlPH2nnTikiwjSC9utnd1UAEJjcChsul0ujRo1SRkaGVq5cqXr16llVF1Bm//2vuaORlyfFx5sTXJs3t7sqAAhcboWNlJQUpaena8GCBYqMjNSBAwckSdHR0br00kstKRAoLZdLeu016dFHzaZdHTpIc+dKsbF2VwYAgc2tno2gi0x2v/vuuxo6dGip3oOlr7CC02lWm7zzjhnfc480ZYrZSwMAUH4e69kox5YcgGUOHTI7gn72mRQcLL38svTQQzSCAoC34NRX+LQvvpBuuUXKyZGio6XZs6Ubb7S7KgDAz3EQG3xWRobUrp0JGldfLa1fT9AAAG9E2IDPcbnMnhn9+0snT0o9epigcc01dlcGALgQplHgU06elIYNkz76yIwffliaNEkK5d9kAPBa/BUNn7F3r9S3r/T559Ill0hTp0rDh9tdFQDg9xA24BOysswOoAcOSFdcIc2bJ3XsaHdVAIDSoGcDXu+996QuXUzQaNpU2riRoAEAvoSwAa9VVCQ98YR0991m066+faW1a6W6de2uDADgDsIGvJLDYcLFiy+a8dNPm6mTypXtrQsA4D56NuB1vvvObNT19ddSpUrSu+9KgwbZXRUAoKwIG/AqK1ZIAwZIx45JtWpJCxZIrVrZXRUAoDyYRoHXmDpV6tnTBI0//tE0ghI0AMD3ETZgu7NnpZQUc2rruXPS4MHSypXmzgYAwPcxjQJbHT0q3XabmT4JCpLS0qTHH+fEVgDwJ4QN2Obrr6U+faTdu80qk/R0MwYA+BemUWCL//xHatvWBI169aR16wgaAOCvCBvwKJdLeuklEyzy86XOnaUNG6QmTeyuDABgFcIGPOb0aSk52fRkuFzSffdJS5eas04AAP6Lng14xP79Uv/+5kC1kBDptdfM6hMaQQHA/xE2YLlNm8zW4z/+KF1+uTRnjnTDDXZXBQDwFKZRYKmPPjIntP74o3TttaY/g6ABAIGFsAFLFBdLf/mLNHCgdOqUlJhoplD+8Ae7KwMAeBrTKKhwhYXmWPh588x4zBhp4kTTqwEACDyEDVSoH34w/RlffCGFhUnTppkVKACAwEXYQIX57DOpXz/p8GGpenUpI0NKSLC7KgCA3ejZQIV45x2pa1cTNK67zpzYStAAAEiEDZTTuXNSaqo0fLg5vXXAAGn1aikuzu7KAADegmkUlNmJE9KgQdJ//2vG48ZJzzwjBRNhAQA/Q9hAmXz7rXTLLdKOHdJll0kzZpi7GgAA/BJhA25btky6/XZzZyMuTlq4UGrRwu6qAADeihveKDWXS3r9dbNB14kTpgF040aCBgDgtxE2UCpnzphTWh9+WCoqkoYOlVasMEtcAQD4LUyj4HcdPmz6MVatMs2fL75oVqBwYisAoDQIG/hNX34p3dL/nDTgv6qTIL3a4UYl9eZfGwBA6TGNgotasEBq107KyfnfYz172lcPAMA3ETbwKy6X9PzzUlKSOVStSxe7KwIA+DLCBs5z6pQ0eLD09NNm/OCD5owTAADKisl3lPjxR3M3IztbCg2VJk82K1BOnrG7MgCALyNsQJK0YYMJGvv3SzEx0ty5UufOdlcFAPAHTKNA6elSp04maDRpYjbqImgAACoKYSOAFRdLY8eaHg2nU+rTR1q7VqpXz+7KAAD+hLARoPLzpX79pIkTzXjsWGn+fCky0tayAAB+iJ6NALRnjzmx9auvpPBw6e23zd0NAACsQNgIMJmZ0q23SkePSjVrmrsZf/yj3VUBAPwZ0ygBZNo0qXt3EzRatTKNoAQNAIDVCBsB4Nw5adQos2fGuXPSoEHmULUrr7S7MgBAIGAaxc8dOybdfrv06adm/Le/mWZQTmwFAHgKYcOPffONWc66a5cUESG9/77ZuAsAAE8ibPipxYvNdInDIdWpIy1cKDVrZndVAIBA5HbPxqpVq9SnTx/VqlVLQUFBmj9/vgVloaxcLunvf5d69zZBo2NH0whK0AAA2MXtsFFYWKjmzZtr8uTJVtSDcnA6pXvukcaMMbuD3nuv9MknUrVqdlcGAAhkbk+jJCYmKjEx0YpaUA4HD0r9+5vtxoODpVdeMStQaAQFANjN8p4Np9Mpp9NZMnY4HFZ/ZMDZvFnq21fKzZWqVJE++kjq0cPuqgAAMCzfZyMtLU3R0dElV1xcnNUfGVDmzpU6dDBBo0EDaf16ggYAwLtYHjbGjh2rvLy8kis3N9fqjwwIxcXSc89JAwZIJ09KN95ogkaDBnZXBgDA+SyfRgkPD1d4eLjVHxNQCguloUOljz8240cekV58UQplITMAwAvx9eRjcnNNf8bmzdIll0hvvGFWoAAA4K3cDhsFBQXatWtXyXjPnj3asmWLqlatqvj4+AotDudbt07q18+sPKlWTZo3z/RrAADgzdwOG9nZ2eratWvJODU1VZKUnJys6dOnV1hhON+MGdKf/iSdOSM1by4tWGB2BgUAwNu5HTa6dOkil8tlRS24gKIi6cknpUmTzLhfP2nmTKlyZXvrAgCgtDhi3ovl5Um33PK/oPGXv5imUIIGAMCX0CDqpXbtMkFj+3bp0kul6dPNUfEAAPgawoYXWr7c7J9x/Lh05ZWmP6NlS7urAgCgbJhG8TJTpkg9e5qg0aaNObGVoAEA8GWEDS9x9qx0//1SSoppCh0yRFq5UqpZ0+7KAAAoH6ZRvMCRI2baJDPTnNL6wgvmmHhObAUA+APChs22bZP69JH27JEiI6X0dKl3b7urAgCg4jCNYqN//Utq29YEjauuMjuEEjQAAP6GsGEDl8tMlfTtKxUUSF26SBs2SI0b210ZAAAVj7DhYadPS3ffbXYFdblMU+jSpVJMjN2VAQBgDXo2PGj/fikpydzFCAmR/vEPEzYAAPBnhA0Pyc42QePHH6WqVc224z87zw4AAL/FNIoHzJ4tdexogkbDhubORiAGjWuvvVZvvfWW3WUAADyMsGGh4mLpmWekQYNMr0avXlJWllS/vt2Ved6pU6e0a9cuNW/e3O5SAAAexjSKRQoKTCNoRoYZP/649PzzplcjEH311VdyuVxq0qSJ3aUAADyMOxsW+P57qX17EzTCwqSZM81S10AMGlu2bFG3bt3UoUMHFRcXKz4+Xq+88ordZQEAPIg7GxVs9Wqpf3+zBXn16tL8+WbjrkD03XffqXPnznrssccUExOj4uJitW7dWqmpqerYsaNatWpld4kAAA/gzkYFevtt6YYbTNC4/npzYmugBg1JGjlypPr3768///nPysnJUUJCgh5//HFVqVJFq1evtrs8AICHEDYqwLlz0ujR0r33mtNbb7/d3OGIi7O7MvscOHBAy5cv18iRI1VUVKStW7fquuuuU3BwsEJDQxUWFmZ3iQAAD2EapZyOHzerTZYuNePx46U//5kTW7OyslRcXKwWLVrom2++0alTp9SiRQvl5ubqyJEjat++vd0lAgA8hLBRDjt2SLfcIn37rXTZZdJ775l+DUhnzpyRJJ0+fVpbtmxR7dq1FRMTo1deeUWNGjVSixYt7C0QAOAxhI0yWrrUTJfk5Unx8dKCBRLfn//Ttm1bhYaGavz48SooKFD9+vU1ZcoUvfLKK1qxYoXd5QEAPIiw4SaXS3r9dSk11Wza1b69NG+eFBtrd2XeJT4+Xu+8846eeOIJ7d+/X6GhoTp58qQWLVqkP/7xj3aXBwDwIBpE3XDmjDRihGkGLS6Whg2TPv2UoHExQ4YM0b59+3T55Zdrzpw52rBhgzp37mx3WQAAD+PORikdOiTdequ0Zo0UHCxNmmRCR6A3gv6evXv36vjx42ratKndpQAAbELYKIUvvjCNoDk5UnS0OVjtxhvtrso3bN26VREREbrqqqvsLgUAYBOmUX5HRobpy8jJka6+Wlq/nqDhjsTERBUUFCiIW0AAELAIGxfhckkTJpilrIWFUvfuJmhcc43dlQEA4FsIGxdw8qR0553meHhJeughafFi6fLL7a0LAABfRM/GL+zdKyUlSZs2SZdcIv2//2dWoAAAgLIhbPzM+vUmaBw4IF1xhTR3rtSpk91VAQDg25hG+T/vvy917myCRtOm5sRWggYAAOUX8GGjqEh68klpyBDJ6ZT69pU++0yqW9fuygAA8A8BHTYcDjNt8sILZvzUU2br8chIW8sCAMCvBGzPxu7dZqOubdukSpWkd96R7rjD7qoAAPA/ARk2VqyQBgyQjh2TatWS5s+XWre2uyoAAPxTwE2jvPGG1LOnCRqtW5tGUIIGAADWCZiwcfaslJIi3X+/dO6c2bQrM9Pc2QAAANYJiGmUY8ek226Tli83p7Q+/7z0xBOc2AoAgCf4fdj4+mvTCPrdd1LlytIHH5gxAADwDL8OG4sWSYMGSfn5Zt+MhQvNhl0AAMBz/LJnw+WSJk2Sevc2QaNzZ9MIStAAAMDz/C5snD4tDR0qPfaYCR1/+pO0dKk56wQAAHieX02jHDgg9esnZWVJISHSq6+aFSg0ggIAYB+/CRubN5vGz717pSpVpDlzpO7d7a4KAAD4xTTKnDlS+/YmaFx7rbRhA0EDAABv4dNho7hYevZZ6fbbpVOnpJtuMlMoV19td2UAAOAnPjuNUlgoJSdLc+ea8aOPmtNbQ0LsrQsAAJzP68NGofOc3l6zR+nrc3Qo/7RiIyvpprpXKePFuvryiyCFhUlvvmlWoAAAAO9TpmmUKVOmqF69eqpUqZJatmyp1atXV3RdkkzQGPjmOr36ybc64DitYpf0/deX6q8jaunLL4JULdalFSsIGgAAeDO3w8bs2bM1evRoPf3009q8ebM6duyoxMRE5eTkVHhxb6/Zo6/3O1TsMuOCrbV1cFYbFZ8MV1hsnh545Xu1a1fhHwsAACqQ22Hj5Zdf1vDhw3XvvfeqYcOGevXVVxUXF6epU6de8PlOp1MOh+O8q7TS1+eo2CW5iqVjyxvq6KLmUlGILmuwX9UHr9OS73e7Wz4AAPAwt8LGmTNntGnTJvXs2fO8x3v27Km1a9de8DVpaWmKjo4uueLi4kr9eYfyT0uSzh6trPzP60iSott/qyuSPldwWFHJr8Nal4WF6vuJvfT9xF66LMzr23wAAF7GrbBx5MgRFRUVqXr16uc9Xr16dR04cOCCrxk7dqzy8vJKrtzc3FJ/XmxkJUlSWLUCxSR+qSv6blKVDjtLdgT96dcBAID3KtN/pgb9Yv9vl8v1q8d+Eh4ervDw8LJ8jO5sE69XP/lWxS6pcuN95/1acJD5dQAA4N3curNxxRVXKCQk5Fd3MQ4dOvSrux0VYXiHempUM0rBv8gxwUFSo5pRGt6hXoV/JgAAqFhuhY2wsDC1bNlSy5YtO+/xZcuWqZ0Fy0IiwkM1+74Eje7eQDWiKik4SKoRVUmjuzfQ7PsSFBFO/wAAAN7O7W/r1NRUDRkyRK1atVJCQoKmTZumnJwcjRw50or6FBEeqoduuFoP3cAe5AAA+CK3w8bAgQN19OhRjR8/Xvv371eTJk20aNEi1alTx4r6AACAjwtyuVwuT36gw+FQdHS08vLyFBUV5cmPBgAAZVSe72+fPvUVAAB4P8IGAACwFGEDAABYyuNrR39qEXHnjBQAAGCvn763y9Lq6fGwkZ+fL0lunZECAAC8w9GjRxUdHe3Wazy+GqW4uFj79u1TZGTkRbc4vxCHw6G4uDjl5uayisUG/Pztx5+Bvfj524ufv/3y8vIUHx+v48ePq0qVKm691uN3NoKDg1W7du0yvz4qKop/0WzEz99+/BnYi5+/vfj52y842P12TxpEAQCApQgbAADAUj4TNsLDw/Xss8+W+bh6lA8/f/vxZ2Avfv724udvv/L8GXi8QRQAAAQWn7mzAQAAfBNhAwAAWIqwAQAALEXYAAAAliJsAAAAS/lE2JgyZYrq1aunSpUqqWXLllq9erXdJQWMVatWqU+fPqpVq5aCgoI0f/58u0sKKGlpaWrdurUiIyMVGxurpKQk7dixw+6yAsrUqVPVrFmzkp0rExIStHjxYrvLClhpaWkKCgrS6NGj7S4lIIwbN05BQUHnXTVq1HD7fbw+bMyePVujR4/W008/rc2bN6tjx45KTExUTk6O3aUFhMLCQjVv3lyTJ0+2u5SAlJmZqZSUFGVlZWnZsmU6d+6cevbsqcLCQrtLCxi1a9fWxIkTlZ2drezsbHXr1k19+/bVtm3b7C4t4GzcuFHTpk1Ts2bN7C4loDRu3Fj79+8vubZu3er2e3j9Phtt2rTR9ddfr6lTp5Y81rBhQyUlJSktLc3GygJPUFCQMjIylJSUZHcpAevw4cOKjY1VZmamOnXqZHc5Aatq1ap66aWXNHz4cLtLCRgFBQW6/vrrNWXKFE2YMEEtWrTQq6++andZfm/cuHGaP3++tmzZUq738eo7G2fOnNGmTZvUs2fP8x7v2bOn1q5da1NVgH3y8vIkmS87eF5RUZFmzZqlwsJCJSQk2F1OQElJSVGvXr3UvXt3u0sJODt37lStWrVUr149DRo0SLt373b7PTx+6qs7jhw5oqKiIlWvXv28x6tXr64DBw7YVBVgD5fLpdTUVHXo0EFNmjSxu5yAsnXrViUkJOj06dOqXLmyMjIy1KhRI7vLChizZs3Spk2blJ2dbXcpAadNmzaaOXOmGjRooIMHD2rChAlq166dtm3bppiYmFK/j1eHjZ8EBQWdN3a5XL96DPB3Dz74oL788kutWbPG7lICzjXXXKMtW7boxIkTmjt3rpKTk5WZmUng8IDc3Fw9/PDDWrp0qSpVqmR3OQEnMTGx5J+bNm2qhIQE1a9fXzNmzFBqamqp38erw8YVV1yhkJCQX93FOHTo0K/udgD+bNSoUVq4cKFWrVql2rVr211OwAkLC9Mf/vAHSVKrVq20ceNGvfbaa3rzzTdtrsz/bdq0SYcOHVLLli1LHisqKtKqVas0efJkOZ1OhYSE2FhhYImIiFDTpk21c+dOt17n1T0bYWFhatmypZYtW3be48uWLVO7du1sqgrwHJfLpQcffFDz5s3T8uXLVa9ePbtLgsyfi9PptLuMgHDDDTdo69at2rJlS8nVqlUrDR48WFu2bCFoeJjT6dT27dtVs2ZNt17n1Xc2JCk1NVVDhgxRq1atlJCQoGnTpiknJ0cjR460u7SAUFBQoF27dpWM9+zZoy1btqhq1aqKj4+3sbLAkJKSovT0dC1YsECRkZEld/mio6N16aWX2lxdYHjqqaeUmJiouLg45efna9asWVq5cqWWLFlid2kBITIy8lc9ShEREYqJiaF3yQPGjBmjPn36KD4+XocOHdKECRPkcDiUnJzs1vt4fdgYOHCgjh49qvHjx2v//v1q0qSJFi1apDp16thdWkDIzs5W165dS8Y/zdElJydr+vTpNlUVOH5a8t2lS5fzHn/33Xc1dOhQzxcUgA4ePKghQ4Zo//79io6OVrNmzbRkyRL16NHD7tIAy+3du1d33HGHjhw5omrVqqlt27bKyspy+zvY6/fZAAAAvs2rezYAAIDvI2wAAABLETYAAIClCBsAAMBShA0AAGApwgYAALAUYQMAAFiKsAEAACxF2AAAAJYibAAAAEsRNgAAgKX+P7VfPwFO9OPuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot([0, 3], [0, 4], 'b')\n",
    "ax.vlines(1, ymin=0, ymax=4/3)\n",
    "ax.scatter(0, 0, s=30)\n",
    "\n",
    "# arrowhead!\n",
    "ax.vlines(3, ymin=3.7, ymax=4, colors='b')\n",
    "ax.hlines(4, xmin=2.8, xmax=3, colors='b')\n",
    "ax.annotate('$\\phi$', xy=(1.1, 0.5))\n",
    "ax.annotate('|v| = 5', xy=(0.9, 2.3))\n",
    "ax.set_xlim(right=5)\n",
    "ax.set_ylim(top=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been working all along with arrays and data frames that have a tabular structure of rows and columns. Such a 2-dimensional structure of numerical elements is known in linear algebra as a **matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23, 'Ideal', 'E', 'SI2', 61.5, 55.0, 326, 3.95, 3.98, 2.43],\n",
       "       [0.21, 'Premium', 'E', 'SI1', 59.8, 61.0, 326, 3.89, 3.84, 2.31],\n",
       "       [0.23, 'Good', 'E', 'VS1', 56.9, 65.0, 327, 4.05, 4.07, 2.31],\n",
       "       [0.29, 'Premium', 'I', 'VS2', 62.4, 58.0, 334, 4.2, 4.23, 2.63],\n",
       "       [0.31, 'Good', 'J', 'SI2', 63.3, 58.0, 335, 4.34, 4.35, 2.75]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gems.head().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want 3- or even higher-dimensional objects. Think for example of a digital image where we record the red, green, and blue values *for each pixel in the 2d array*. The linear algebraic abstraction we need for such an object is called a **tensor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4, 1. , 0.7, 0.6, 0.2],\n",
       "        [0.2, 0.1, 0.9, 0.6, 0.7],\n",
       "        [0. , 1. , 0.8, 0.2, 0.2],\n",
       "        [0.2, 0.3, 0.5, 0.4, 0.3],\n",
       "        [0.6, 0.1, 0.3, 0.4, 0.5]],\n",
       "\n",
       "       [[0.8, 0.2, 0.5, 0.6, 0. ],\n",
       "        [0.6, 0.2, 0.1, 0.9, 1. ],\n",
       "        [0.8, 0.3, 0.1, 0.7, 0.4],\n",
       "        [0.1, 0.5, 0. , 0.9, 0.3],\n",
       "        [0.7, 0.3, 0.5, 0.5, 0.2]],\n",
       "\n",
       "       [[1. , 0.8, 0.9, 0.9, 0.6],\n",
       "        [0.9, 0.1, 0.2, 0. , 0.3],\n",
       "        [0.4, 0.3, 0.8, 0.4, 0.3],\n",
       "        [0.5, 0.1, 0.8, 0.1, 1. ],\n",
       "        [0.8, 0.2, 0. , 0.8, 0.7]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "tensor = np.round(np.random.rand(3, 5, 5), 1)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices can be added and multiplied, and there are other distinctive operations on matrices that are often useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Matrix Addition</b>: Click for Illustration</summary>\n",
    "$\\begin{bmatrix}\n",
    "a_{11} & a_{12} \\\\\n",
    "a_{21} & a_{22}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "b_{11} & b_{12} \\\\\n",
    "b_{21} & b_{22}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{11} + b_{11} & a_{12} + b_{12} \\\\\n",
    "a_{21} + b_{21} & a_{22} + b_{22}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 4],\n",
       "       [8, 5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "my_matrix1 = np.random.randint(low=1, high=11, size=(2, 2))\n",
    "my_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 10],\n",
       "       [ 3,  7]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix2 = np.random.randint(low=1, high=11, size=(2, 2))\n",
    "my_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 14],\n",
       "       [11, 12]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix1 + my_matrix2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<details>\n",
    "    <summary><b>Matrix Multiplication</b>: Click for Illustration</summary>\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} \\\\\n",
    "a_{2,1} & a_{2,2}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "b_{1,1} & b_{1,2} \\\\\n",
    "b_{2,1} & b_{2,2}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{1,1}\\times b_{1,1} + a_{1,2}\\times b_{2,1} & a_{1,1}\\times b_{1,2} + a_{1,2}\\times b_{2,2} \\\\\n",
    "a_{2,1}\\times b_{1,1} + a_{2,2}\\times b_{2,1} & a_{2,1}\\times b_{1,2} + a_{2,2}\\times b_{2,2}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61,  98],\n",
       "       [ 71, 115]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix1.dot(my_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many times when we need to measure distances. For example, many modeling algorithms rely on a notion of **similarity** between data points. But we have already seen how distance is used to construct a linear model: Choose the betas that minimize the sum of squared **distances** between true and predicted $y$-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider this distance for *all* data points at once: We can think of that as a vector: $\\vec{(y_i - \\hat{y_i})^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in fact there are multiple ways to measure the magnitude of a vector. Typically, we are thinking of Euclidean spaces and so use the **L2 norm** to measure the magnitude of a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vec = np.array([3, 4, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(3**2 + 4**2 + 12**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(my_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are other norms we can use. In general, the **$n$-norm** will calculate $(x_1^n + ... + x_m^n)^{\\frac{1}{n}}$ for a vector $\\vec{x_i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(my_vec, ord=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can express covariance and correlation matrices as linear-algebraic transformations:\n",
    "\n",
    "For a centered data matrix $M$:\n",
    "- $cov(M) = \\frac{1}{n-1}M^TM$, where $n$ is the number of observations.\n",
    "\n",
    "A centered data matrix is one whose column means are all 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This equation makes use of the **transpose** of a matrix $M$, $M^T$, which is the matrix that results from swapping the rows and columns of $M$. You can also think of this as a *reflection* of the elements of $M$ about the main diagonal of $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 4],\n",
       "       [8, 5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 8],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix_transposed = my_matrix1.T\n",
    "my_matrix_transposed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate this equation. Suppose we have ten observations (rows) for each of three variables (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37454012, 0.95071431, 0.73199394],\n",
       "       [0.59865848, 0.15601864, 0.15599452],\n",
       "       [0.05808361, 0.86617615, 0.60111501],\n",
       "       [0.70807258, 0.02058449, 0.96990985],\n",
       "       [0.83244264, 0.21233911, 0.18182497],\n",
       "       [0.18340451, 0.30424224, 0.52475643],\n",
       "       [0.43194502, 0.29122914, 0.61185289],\n",
       "       [0.13949386, 0.29214465, 0.36636184],\n",
       "       [0.45606998, 0.78517596, 0.19967378],\n",
       "       [0.51423444, 0.59241457, 0.04645041]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "mat_1 = np.random.rand(10, 3)\n",
    "mat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_1_centered = mat_1 - np.mean(mat_1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06245653, -0.03833006, -0.01323947],\n",
       "       [-0.03833006,  0.10612618, -0.00378735],\n",
       "       [-0.01323947, -0.00378735,  0.08823377]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_1_centered.T.dot(mat_1_centered) / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06245653, -0.03833006, -0.01323947],\n",
       "       [-0.03833006,  0.10612618, -0.00378735],\n",
       "       [-0.01323947, -0.00378735,  0.08823377]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = np.cov(mat_1, rowvar=False)\n",
    "\n",
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Bonus: Correlation Matrices</summary>\n",
    "    To calculate a correlation matrix, we can multiply the covariance matrix on both sides by a diagonal matrix of the reciprocals of the standard deviations of the columns. [Source](https://blogs.sas.com/content/iml/2010/12/10/converting-between-correlation-and-covariance-matrices.html)\n",
    "\n",
    "<code>stds = np.sqrt(np.diag(cov))\n",
    "np.diag(stds\\*\\*-1).dot(cov).dot(np.diag(stds\\*\\*-1))\n",
    "np.corrcoef(mat_1, rowvar=False)\n",
    "</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving a System of Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In elementary algebra we start by solving one equation for one unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image from mathelp.org](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSnrLW6J0FYge6zWDKqRrAtWx4Jf0HkhMiwHQ&usqp=CAU) source: mathelp.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear algebra gives us the tools to solve many equations simultaneously. Suppose we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{align}\n",
    " x_1 - 2x_2 + 3x_3 &= 9 \\\\\n",
    " 2x_1 - 5x_2 + 10x_3 &= 4 \\\\\n",
    " 6x_3 &= 0 \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write these equations as a single matrix equation:\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} \n",
    "    1 & -2 & 3 \\\\\n",
    "    2 & -5 & 10 \\\\\n",
    "    0 & 0 & 6\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "    x_1 \\\\\n",
    "    x_2 \\\\\n",
    "    x_3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "    9 \\\\\n",
    "    4 \\\\\n",
    "    0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or: $A\\vec{x} = \\vec{b}$, where\n",
    "\n",
    "- $A = \\begin{bmatrix} \n",
    "    1 & -2 & 3 \\\\\n",
    "    2 & -5 & 10 \\\\\n",
    "    0 & 0 & 6\n",
    "\\end{bmatrix}$\n",
    "\n",
    "- $\\vec{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}$, and\n",
    "\n",
    "- $\\vec{b} = \\begin{bmatrix} 9 \\\\ 4 \\\\ 0 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we're solving for a *vector* of unknowns. To solve $A\\vec{x} = \\vec{b}$ for $x$, we multiply both sides of the equation by **$A^{-1}$, the inverse of $A$**:\n",
    "\n",
    "$A^{-1}A\\vec{x} = \\vec{x} = A^{-1}b$\n",
    "\n",
    "In just the way that multiplying a scalar by its multiplicative inverse produces 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42 * 42**-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so multiplying a matrix by its matrix inverse produces $I$, the **identity matrix**, a square matrix with 1's down the main diagonal and 0's everywhere else.\n",
    "\n",
    "> $$\\begin{align}\n",
    "    I_3 &= \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    I_5 &= \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "                           0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "                           0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "                           0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "                           0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "                           0 & 0 & 0 & 0 & 0 & 1 \\\\                           \n",
    "            \\end{bmatrix}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse and identity matrices have important properties:\n",
    "\n",
    "- $IA = A$\n",
    "- $AI = A$\n",
    "- $AA^{-1} = I$\n",
    "- $A^{-1}A = I$\n",
    "- $I\\vec{x} = \\vec{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[ 1 -2  3]\n",
      " [ 2 -5 10]\n",
      " [ 0  0  6]]\n",
      "\n",
      "b:\n",
      "[[9]\n",
      " [4]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, -2,  3],\n",
    "    [2, -5, 10],\n",
    "    [0,  0,  6]\n",
    "])\n",
    "\n",
    "b = np.array([9, 4, 0]).reshape(3, 1)\n",
    "\n",
    "print('A:')\n",
    "print(A)\n",
    "print()\n",
    "print('b:')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.         -2.          0.83333333]\n",
      " [ 2.         -1.          0.66666667]\n",
      " [ 0.          0.          0.16666667]]\n",
      "x1 = 37.0, x2 = 14.0, x3 = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Find the inverse\n",
    "\n",
    "A_inv = np.linalg.inv(A)\n",
    "print(A_inv)\n",
    "\n",
    "# Getting the solution\n",
    "\n",
    "x1, x2, x3 = A_inv @ b\n",
    "print(f\"x1 = {x1[0]}, x2 = {x2[0]}, x3 = {x3[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.],\n",
       "       [4.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.dot(np.array([x1, x2, x3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve It Faster with NumPy's `linalg.solve()`\n",
    "\n",
    "NumPy's ```linalg``` module has a ```.solve()``` method that you can use to solve a system of linear equations!\n",
    "\n",
    "In particular, it will solve for the vector $\\vec{x}$ in the equation $A\\vec{x} = b$. You should know that, \"under the hood\", the ```.solve()``` method does NOT compute the inverse matrix $A^{-1}$. This is largely because of the enormous expense of directly computing a matrix inverse, which takes $\\mathcal{O}(n^3)$ time.\n",
    "\n",
    "Check out [this discussion](https://stackoverflow.com/questions/31256252/why-does-numpy-linalg-solve-offer-more-precise-matrix-inversions-than-numpy-li) on stackoverflow for more on the differences between using `.solve()` and `.inv()`.\n",
    "\n",
    "And check out the documentation for ```.solve()``` [here](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.solve.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.],\n",
       "       [14.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the .solve() method to solve this system of equations\n",
    "\n",
    "A = np.array([\n",
    "    [1, -2,  3],\n",
    "    [2, -5, 10],\n",
    "    [0,  0,  6]\n",
    "])\n",
    "\n",
    "b = np.array([9, 4, 0]).reshape(3, 1)\n",
    "\n",
    "np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we could just solve our matrix equation by calculating the inverse of our matrix $A$ and then multiplying by $b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.],\n",
       "       [14.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(A).dot(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the time difference is striking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.82 µs ± 41.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.linalg.inv(A).dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.98 µs ± 184 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even for a (tiny!) 5x5 matrix, the cost of computing the inverse directly is evident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider now a typical dataset and the associated multiple linear regression problem. We have many observations (rows), each of which consists of a set of values both for the predictors (columns, i.e. the independent variables) and for the target (the dependent variable).\n",
    "\n",
    "For the equation $A\\vec{x} = \\vec{c}$, we can think of the values of the independent variables (i.e. the data matrix, \"X\") as our matrix $A$ of coefficients and of the values of the dependent variable (i.e. the target, \"y\") as our output vector $\\vec{c}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task here is, in effect, to solve for $\\vec{\\beta}$, where we have that $A\\vec{\\beta} = \\vec{c}$, except in general we'll have more rows than columns. But more rows than columns means more equations than unknowns, which means that in general **there is no solution**. This is why instead we go for an optimization--in our case, a best-fit line. So we have $A\\vec{\\beta}\\approx\\vec{c}$.\n",
    "\n",
    "Using $a$ for our independent variables and $c$ for our dependent variable, we have:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta_1\\begin{bmatrix}\n",
    "a_{1,1} \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "a_{m,1}\n",
    "\\end{bmatrix} +\n",
    "... + \\beta_n\\begin{bmatrix}\n",
    "a_{1,n} \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "a_{m,n}\n",
    "\\end{bmatrix} \\approx \\begin{bmatrix}\n",
    "c_1 \\\\\n",
    ".  \\\\\n",
    ".  \\\\\n",
    ".  \\\\\n",
    "c_m\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra Solves the Best-Fit Line Problem\n",
    "\n",
    "If we have a matrix of predictors $X$ and a target column $y$, we can express $\\vec{\\beta}$, the vectorized parameters of the best-fit line, as  follows:\n",
    "\n",
    "$\\large\\vec{\\beta} = (X^TX)^{-1}X^Ty$.\n",
    "\n",
    "$(X^TX)^{-1}X^T$ is sometimes called the *pseudo-inverse* of $X$.\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415,  1.53658231],\n",
       "       [-0.1382643 ,  1.53427025],\n",
       "       [ 0.64768854,  2.24196227],\n",
       "       [ 1.52302986,  0.08671976],\n",
       "       [-0.23415337,  0.27508217],\n",
       "       [-0.23413696,  1.43771247],\n",
       "       [ 1.57921282,  0.98716888],\n",
       "       [ 0.76743473,  2.31424733],\n",
       "       [-0.46947439,  1.09197592],\n",
       "       [ 0.54256004,  0.5876963 ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "preds = np.array(list(zip(np.random.normal(size=10),\n",
    "                          np.array(np.random.normal(size=10, loc=2)))))\n",
    "target = np.array(np.random.exponential(size=10))\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45404034, 0.2599216 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(preds.T.dot(preds)).dot(preds.T).dot(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45404034, 0.2599216 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression(fit_intercept=False).fit(preds, target).coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Taste of What's Coming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues, Singular Values, Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to express a matrix as a **product** of other matrices. Sometimes the gain is only in computational efficiency, but there are also certain factorizations or **decompositions** that are useful in other ways.\n",
    "\n",
    "An **eigendecomposition** reduces a matrix to a collection of vectors that capture the *linear* action of the matrix. Selecting the vectors that produce the largest such linear transformations is the idea behind **principal component analysis**, which is useful for reducing high-dimensional datasets to lower-dimensional problems.\n",
    "\n",
    "Eigendecompositions are possibly only for square matrices; a **singular value decomposition** is a more fundamental matrix factorization that can be applied to any matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do recommendation engines work?\n",
    "\n",
    "Imagine representing your interests (film genres, book subjects, music styles) as a **vector**: larger numbers represent larger preferences. Now do this for multiple people. Now we can think of comparing these vectors directly or against some target such as whether a given product/service was used/bought/watched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When our data is **unlabeled** we have a problem in **unsupervised learning**. One major strategy for this type of problem is to impose a *similarity* metric on our data points. Similarity between data points is measured as some function of the **(vector) distance** between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One similarity metric for vectors is **cosine similarity**, which computes the *cosine of the angle between them*. Note that this is always well-defined for non-zero vectors since any two vectors determine a plane (in which the angle can be measured)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images\n",
    "\n",
    "We saw already above the idea of representing a digital image as a **tensor** of values that encode facts about each pixel in the digitization.\n",
    "\n",
    "**Neural networks** are good for working with tensors of high dimension. Such objects often need to be manipulated into different shapes, and the `.reshape()` method is great for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4, 1. , 0.7, 0.6, 0.2],\n",
       "        [0.2, 0.1, 0.9, 0.6, 0.7],\n",
       "        [0. , 1. , 0.8, 0.2, 0.2],\n",
       "        [0.2, 0.3, 0.5, 0.4, 0.3],\n",
       "        [0.6, 0.1, 0.3, 0.4, 0.5]],\n",
       "\n",
       "       [[0.8, 0.2, 0.5, 0.6, 0. ],\n",
       "        [0.6, 0.2, 0.1, 0.9, 1. ],\n",
       "        [0.8, 0.3, 0.1, 0.7, 0.4],\n",
       "        [0.1, 0.5, 0. , 0.9, 0.3],\n",
       "        [0.7, 0.3, 0.5, 0.5, 0.2]],\n",
       "\n",
       "       [[1. , 0.8, 0.9, 0.9, 0.6],\n",
       "        [0.9, 0.1, 0.2, 0. , 0.3],\n",
       "        [0.4, 0.3, 0.8, 0.4, 0.3],\n",
       "        [0.5, 0.1, 0.8, 0.1, 1. ],\n",
       "        [0.8, 0.2, 0. , 0.8, 0.7]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4, 1. , 0.7, 0.6, 0.2, 0.2, 0.1, 0.9, 0.6, 0.7, 0. , 1. , 0.8,\n",
       "        0.2, 0.2],\n",
       "       [0.2, 0.3, 0.5, 0.4, 0.3, 0.6, 0.1, 0.3, 0.4, 0.5, 0.8, 0.2, 0.5,\n",
       "        0.6, 0. ],\n",
       "       [0.6, 0.2, 0.1, 0.9, 1. , 0.8, 0.3, 0.1, 0.7, 0.4, 0.1, 0.5, 0. ,\n",
       "        0.9, 0.3],\n",
       "       [0.7, 0.3, 0.5, 0.5, 0.2, 1. , 0.8, 0.9, 0.9, 0.6, 0.9, 0.1, 0.2,\n",
       "        0. , 0.3],\n",
       "       [0.4, 0.3, 0.8, 0.4, 0.3, 0.5, 0.1, 0.8, 0.1, 1. , 0.8, 0.2, 0. ,\n",
       "        0.8, 0.7]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.reshape(5, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4, 1. , 0.7, 0.6, 0.2, 0.2, 0.1, 0.9, 0.6, 0.7, 0. , 1. , 0.8,\n",
       "        0.2, 0.2, 0.2, 0.3, 0.5, 0.4, 0.3, 0.6, 0.1, 0.3, 0.4, 0.5, 0.8,\n",
       "        0.2, 0.5, 0.6, 0. , 0.6, 0.2, 0.1, 0.9, 1. , 0.8, 0.3, 0.1, 0.7,\n",
       "        0.4, 0.1, 0.5, 0. , 0.9, 0.3, 0.7, 0.3, 0.5, 0.5, 0.2, 1. , 0.8,\n",
       "        0.9, 0.9, 0.6, 0.9, 0.1, 0.2, 0. , 0.3, 0.4, 0.3, 0.8, 0.4, 0.3,\n",
       "        0.5, 0.1, 0.8, 0.1, 1. , 0.8, 0.2, 0. , 0.8, 0.7]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.reshape(1, 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up: Matrix Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many transformations of *products* of matrices can be expressed in terms of the transformation applied to the factors *in reverse order*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(AB)^T = B^TA^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(low=1, high=11, size=(10, 2))\n",
    "B = np.random.randint(low=1, high=11, size=(2, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92, 134,  46,  80,  72,  38,  76,  40,  84,  92],\n",
       "       [ 74,  88,  24,  57,  37,  30,  60,  22,  54,  48],\n",
       "       [110, 180,  68, 103, 107,  46,  92,  58, 114, 136],\n",
       "       [ 84,  98,  26,  64,  40,  34,  68,  24,  60,  52],\n",
       "       [ 70, 140,  60,  75,  95,  30,  60,  50,  90, 120],\n",
       "       [ 28,  56,  24,  30,  38,  12,  24,  20,  36,  48]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A.dot(B)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92, 134,  46,  80,  72,  38,  76,  40,  84,  92],\n",
       "       [ 74,  88,  24,  57,  37,  30,  60,  22,  54,  48],\n",
       "       [110, 180,  68, 103, 107,  46,  92,  58, 114, 136],\n",
       "       [ 84,  98,  26,  64,  40,  34,  68,  24,  60,  52],\n",
       "       [ 70, 140,  60,  75,  95,  30,  60,  50,  90, 120],\n",
       "       [ 28,  56,  24,  30,  38,  12,  24,  20,  36,  48]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.T.dot(A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(AB)^{-1} = B^{-1}A^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(low=1, high=11, size=(3, 3))\n",
    "B = np.random.randint(low=1, high=11, size=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05294689,  0.14637306, -0.15495466],\n",
       "       [-0.05569948, -0.31606218,  0.29145078],\n",
       "       [-0.06994819, -0.10621762,  0.14507772]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(A.dot(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05294689,  0.14637306, -0.15495466],\n",
       "       [-0.05569948, -0.31606218,  0.29145078],\n",
       "       [-0.06994819, -0.10621762,  0.14507772]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(B).dot(np.linalg.inv(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up: The Determinant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinant\n",
    "\n",
    "The **determinant** of a square matrix $M$, $|M|$, represents the area (or, in higher dimensions, the volume) of the parallelogram (parallelepiped) formed by the rows or columns of $M$. And it is also related to the inverse of $M$.\n",
    "\n",
    "For a 2x2 matrix $\\begin{bmatrix} a & b \\\\ c & d\\end{bmatrix}$, the determinant is equal to $ad - bc$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 4],\n",
       "       [8, 5]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9999999999999996"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(my_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = my_matrix1[0][0]\n",
    "d = my_matrix1[1][1]\n",
    "b = my_matrix1[0][1]\n",
    "c = my_matrix1[1][0]\n",
    "\n",
    "a*d - b*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dba4eb4192a401b10630bbfa25b7fb709bd78a83adcb3ebf371257b880947706"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
